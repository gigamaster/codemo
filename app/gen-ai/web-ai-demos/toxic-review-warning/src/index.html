<!-- Copyright 2024 Google LLC
SPDX-License-Identifier: Apache-2.0 -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Toxic review warning</title>
    <link rel="stylesheet" href="style-core.css" />
    <link rel="stylesheet" href="style-ai.css" />
    <link
      rel="icon"
      href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>☢️</text></svg>"
    />
  </head>
  <body>
    <main>
      <div>
        <h1>Toxic review warning ☢️</h1>
        <div id="toxicityStatusTemp"></div>
        <div class="img-wrapper">
          <img src="book.png" alt="" width="200">
        </div>
        <div>
          <div id="modelStatusWrapper">
            <div id="modelStatus"></div>
          </div>
          <form id="form">
            <div>
              <label for="reviewInputEl">Product review</label>
            </div>
            <div class="input-wrapper">
              <textarea name="reviewInputEl" id="reviewInputEl" oninput="handleUserInputChange()">I freaking hate this book</textarea>
            </div>
            <div class="button-wrapper">
              <div id="aiWrapper">
                <div class="ai-effect-wrapper">
                  <div id="aiEffect"></div>
                </div>
                <div id="toxicityAssessmentEl"></div>
              </div>
              <button type="submit" onclick="simulatePostReview()">
                Post
              </button>
            </div>
          </form>
        </div>
    </main>
    <!-- Your comment is flagged as potentially harmful. -->
    <div class="demo-metadata">
      <h3>About this demo</h3>
      Code by <a href="https://x.com/maudnals" noreferrer noopener>@maudnals</a> ・
      <a
        href="https://github.com/GoogleChromeLabs/web-ai-demos/tree/main/toxic-review-warning" noreferrer noopener
        >See Code + Docs</a
      >
      <p class="demo-explanation">
        <b>Why this demo?</b>
        Online toxicity is an <a href="https://perspectiveapi.com/" noreferrer noopener>existential problem for platforms and publishers</a>, and <a href="https://www.researchgate.net/figure/After-receiving-a-toxic-comment-users-become-less-active-On-average-users-are-more_fig1_376246924" noreferrer noopener>silences</a> important voices in conversation. On a business level, toxic comments can damage a brand's image and  <a href="https://www.nature.com/articles/s41598-024-57783-8" noreferrer noopener>drive customers and users away</a>.
        Here, we use Gen AI (an LLM) to catch toxic comments in real-time. While server-side toxicity screening remains necessary, this approach helps users understand why their comments might be harmful and can reduce the server-side workload.
        <br/><br/>
        <b>Some product reviews to try:</b><br/> ✅ Not toxic: "Too pricey", "I didn't like this book", "I hate this book".<br/> ☢️ Toxic: "This book is crap", "I freaking hate this book", "The author is an idiot".
      </p>
    </div>
    <script type="module" src="script.js"></script>
  </body>
</html>
